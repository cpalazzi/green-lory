{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf65fb3",
   "metadata": {},
   "source": [
    "# 00 – Tech config → PyPSA CSV bundle\n",
    "\n",
    "This notebook is the **canonical input workflow** for techno‑economic assumptions.\n",
    "\n",
    "You provide a YAML file (default: `inputs/tech_config_ammonia_plant.yaml`) with **overnight CAPEX**, **lifetimes**, **interest rates**, and **efficiencies** on an **HHV output basis**.\n",
    "\n",
    "The notebook then:\n",
    "1. converts overnight CAPEX into annualised PyPSA `capital_cost` using the annuity payment $\\text{Annuity}(r,n)=\\frac{r(1+r)^n}{(1+r)^n-1}$ plus fixed O&M fraction,\n",
    "2. converts link CAPEX from **MW_out** to PyPSA’s **MW_in** basis,\n",
    "3. writes the updated component tables into `basic_ammonia_plant/` (`generators.csv`, `links.csv`, `stores.csv`).\n",
    "\n",
    "At runtime the solver reads only the CSV bundle; no YAML is applied by the model code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Literal, Tuple\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Repo paths (robust: walk upwards until we find the project root)\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for candidate in [start, *start.parents]:\n",
    "        if (candidate / \"basic_ammonia_plant\").exists() and (candidate / \"model\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"Could not locate repo root (expected basic_ammonia_plant/ and model/)\")\n",
    "\n",
    "repo_root = find_repo_root(Path().resolve())\n",
    "PLANT_DIR = repo_root / \"basic_ammonia_plant\"\n",
    "DEFAULT_TECH_YAML = repo_root / \"inputs\" / \"tech_config_ammonia_plant.yaml\"\n",
    "\n",
    "print(\"Repo root:\", repo_root)\n",
    "print(\"Plant CSV dir:\", PLANT_DIR)\n",
    "print(\"Default tech YAML:\", DEFAULT_TECH_YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d179ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# USER PARAMETERS\n",
    "# ----------------\n",
    "# Point this at your YAML file (same schema as inputs/tech_config_ammonia_plant.yaml).\n",
    "TECH_YAML = DEFAULT_TECH_YAML\n",
    "\n",
    "# Set to True to actually overwrite basic_ammonia_plant/*.csv\n",
    "WRITE_OUTPUTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeff548",
   "metadata": {},
   "outputs": [],
   "source": [
    "TechType = Literal[\"generator\", \"link\", \"store\"]\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TechEntry:\n",
    "    name: str\n",
    "    component_type: TechType\n",
    "    overnight_cost_per_mw: float | None = None\n",
    "    overnight_cost_per_mwh: float | None = None\n",
    "    lifetime_years: float = 20.0\n",
    "    interest_rate: float = 0.07\n",
    "    fixed_om_fraction: float = 0.0\n",
    "    # For links: optional bus-based recipe per 1 unit of primary output (bus1).\n",
    "    carriers_in: Dict[str, float] | None = None\n",
    "    carriers_out: Dict[str, float] | None = None\n",
    "    overall_efficiency: float | None = None\n",
    "\n",
    "\n",
    "def annuity_factor(interest_rate: float, lifetime_years: float) -> float:\n",
    "    if lifetime_years <= 0:\n",
    "        raise ValueError(\"lifetime_years must be positive\")\n",
    "    if abs(interest_rate) < 1e-12:\n",
    "        return 1.0 / lifetime_years\n",
    "    factor = (1.0 + interest_rate) ** lifetime_years\n",
    "    return interest_rate * factor / (factor - 1.0)\n",
    "\n",
    "\n",
    "def annualised_capital_cost(overnight_cost: float, interest_rate: float, lifetime_years: float, fixed_om_fraction: float) -> float:\n",
    "    crf = annuity_factor(interest_rate, lifetime_years)\n",
    "    return float(overnight_cost) * (crf + float(fixed_om_fraction))\n",
    "\n",
    "\n",
    "def link_cost_mw_out_to_mw_in(cost_per_mw_out: float, efficiency_bus0_to_bus1: float) -> float:\n",
    "    # In PyPSA: p_bus1 = p_nom * efficiency (where p_nom is MW_in on bus0).\n",
    "    # YAML link costs are quoted per MW_out (bus1). Convert to per MW_in by multiplying by efficiency.\n",
    "    if efficiency_bus0_to_bus1 <= 0:\n",
    "        raise ValueError(\"Link efficiency (bus0->bus1) must be positive\")\n",
    "    return float(cost_per_mw_out) * float(efficiency_bus0_to_bus1)\n",
    "\n",
    "\n",
    "def _coerce_float_map(value: Any, field: str) -> Dict[str, float] | None:\n",
    "    if value is None:\n",
    "        return None\n",
    "    if not isinstance(value, dict):\n",
    "        raise ValueError(f\"{field} must be a mapping\")\n",
    "    out: Dict[str, float] = {}\n",
    "    for k, v in value.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        out[str(k)] = float(v)\n",
    "    return out or None\n",
    "\n",
    "\n",
    "def load_tech_yaml(path: Path) -> Dict[str, TechEntry]:\n",
    "    data = yaml.safe_load(path.read_text()) or {}\n",
    "    techs = data.get(\"techs\")\n",
    "    if not isinstance(techs, dict):\n",
    "        raise ValueError(\"YAML must have a top-level 'techs:' mapping\")\n",
    "    parsed: Dict[str, TechEntry] = {}\n",
    "    for name, raw in techs.items():\n",
    "        if not isinstance(raw, dict):\n",
    "            raise ValueError(f\"techs.{name} must be a mapping\")\n",
    "        component_type = raw.get(\"component_type\")\n",
    "        if component_type not in (\"generator\", \"link\", \"store\"):\n",
    "            raise ValueError(f\"techs.{name}.component_type must be one of generator/link/store\")\n",
    "        entry = TechEntry(\n",
    "            name=name,\n",
    "            component_type=component_type,\n",
    "            overnight_cost_per_mw=raw.get(\"overnight_cost_per_mw\"),\n",
    "            overnight_cost_per_mwh=raw.get(\"overnight_cost_per_mwh\"),\n",
    "            lifetime_years=float(raw.get(\"lifetime_years\", 20.0)),\n",
    "            interest_rate=float(raw.get(\"interest_rate\", 0.07)),\n",
    "            fixed_om_fraction=float(raw.get(\"fixed_om_fraction\", 0.0)),\n",
    "            carriers_in=_coerce_float_map(raw.get(\"carriers_in\"), f\"techs.{name}.carriers_in\"),\n",
    "            carriers_out=_coerce_float_map(raw.get(\"carriers_out\"), f\"techs.{name}.carriers_out\"),\n",
    "            overall_efficiency=(None if raw.get(\"overall_efficiency\") in (None, \"\") else float(raw.get(\"overall_efficiency\"))),\n",
    "        )\n",
    "        if entry.component_type in (\"generator\", \"link\") and entry.overnight_cost_per_mw is None:\n",
    "            raise ValueError(f\"techs.{name} is {entry.component_type} but has no overnight_cost_per_mw\")\n",
    "        if entry.component_type == \"store\" and entry.overnight_cost_per_mwh is None:\n",
    "            raise ValueError(f\"techs.{name} is store but has no overnight_cost_per_mwh\")\n",
    "        parsed[name] = entry\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358fc00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_bundle(plant_dir: Path) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    buses = pd.read_csv(plant_dir / \"buses.csv\").set_index(\"name\", drop=False)\n",
    "    gens = pd.read_csv(plant_dir / \"generators.csv\")\n",
    "    links = pd.read_csv(plant_dir / \"links.csv\")\n",
    "    stores = pd.read_csv(plant_dir / \"stores.csv\")\n",
    "    for df_name, df in [(\"generators\", gens), (\"links\", links), (\"stores\", stores)]:\n",
    "        if \"name\" not in df.columns:\n",
    "            raise ValueError(f\"{df_name}.csv must have a 'name' column\")\n",
    "    gens = gens.set_index(\"name\", drop=False)\n",
    "    links = links.set_index(\"name\", drop=False)\n",
    "    stores = stores.set_index(\"name\", drop=False)\n",
    "    return buses, gens, links, stores\n",
    "\n",
    "\n",
    "def _recipe_from_link_row(link_row: pd.Series) -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "    \"\"\"Return (carriers_in, carriers_out) per 1 unit of bus1 output, derived from link coefficients.\"\"\"\n",
    "    bus0 = str(link_row[\"bus0\"])\n",
    "    bus1 = str(link_row[\"bus1\"])\n",
    "    eff1 = float(link_row[\"efficiency\"])\n",
    "    if eff1 <= 0:\n",
    "        raise ValueError(f\"Link {link_row['name']} has non-positive bus1 efficiency; cannot normalise\")\n",
    "\n",
    "    # p0 required per 1 unit output on bus1\n",
    "    p0_per_out = 1.0 / eff1\n",
    "    carriers_in: Dict[str, float] = {bus0: p0_per_out}\n",
    "    carriers_out: Dict[str, float] = {bus1: 1.0}\n",
    "\n",
    "    # Optional bus2 handling\n",
    "    bus2 = link_row.get(\"bus2\")\n",
    "    if bus2 is not None and str(bus2).strip() not in (\"\", \"nan\", \"NaN\"):\n",
    "        bus2_name = str(bus2)\n",
    "        eff2 = link_row.get(\"efficiency2\")\n",
    "        if eff2 not in (None, \"\") and not (isinstance(eff2, float) and math.isnan(eff2)):\n",
    "            eff2 = float(eff2)\n",
    "            flow_per_out = eff2 / eff1  # p2 per 1 unit bus1 output\n",
    "            if flow_per_out >= 0:\n",
    "                carriers_out[bus2_name] = flow_per_out\n",
    "            else:\n",
    "                carriers_in[bus2_name] = -flow_per_out\n",
    "\n",
    "    return carriers_in, carriers_out\n",
    "\n",
    "\n",
    "def _overall_efficiency(carriers_in: Dict[str, float], carriers_out: Dict[str, float]) -> float | None:\n",
    "    total_in = sum(float(v) for v in carriers_in.values() if v is not None)\n",
    "    total_out = sum(float(v) for v in carriers_out.values() if v is not None)\n",
    "    if total_in <= 0:\n",
    "        return None\n",
    "    return total_out / total_in\n",
    "\n",
    "\n",
    "def _warn_if_recipe_mismatch(\n",
    "    name: str,\n",
    "    yaml_in: Dict[str, float] | None,\n",
    "    yaml_out: Dict[str, float] | None,\n",
    "    derived_in: Dict[str, float],\n",
    "    derived_out: Dict[str, float],\n",
    "    yaml_eff: float | None,\n",
    "    tolerance: float = 1e-3,\n",
    "    eff_tolerance: float = 2e-2,\n",
    " ) -> None:\n",
    "    if not yaml_in or not yaml_out:\n",
    "        return\n",
    "    # Compare only keys that overlap; warn on missing/extra.\n",
    "    yaml_in_keys = set(yaml_in.keys())\n",
    "    yaml_out_keys = set(yaml_out.keys())\n",
    "    derived_in_keys = set(derived_in.keys())\n",
    "    derived_out_keys = set(derived_out.keys())\n",
    "\n",
    "    extra = (yaml_in_keys | yaml_out_keys) - (derived_in_keys | derived_out_keys)\n",
    "    missing = (derived_in_keys | derived_out_keys) - (yaml_in_keys | yaml_out_keys)\n",
    "    if extra:\n",
    "        print(f\"WARNING: {name} YAML recipe has keys not on link ports: {sorted(extra)}\")\n",
    "    if missing:\n",
    "        print(f\"WARNING: {name} YAML recipe missing ports present on link: {sorted(missing)}\")\n",
    "\n",
    "    def _cmp(label: str, left: Dict[str, float], right: Dict[str, float]):\n",
    "        for k in sorted(set(left.keys()) & set(right.keys())):\n",
    "            lv = float(left[k])\n",
    "            rv = float(right[k])\n",
    "            if rv == 0 and lv == 0:\n",
    "                continue\n",
    "            denom = max(1.0, abs(rv))\n",
    "            if abs(lv - rv) / denom > tolerance:\n",
    "                print(f\"WARNING: {name} {label} mismatch for '{k}': yaml={lv:.6g} derived={rv:.6g}\")\n",
    "\n",
    "    _cmp(\"carriers_in\", yaml_in, derived_in)\n",
    "    _cmp(\"carriers_out\", yaml_out, derived_out)\n",
    "\n",
    "    if yaml_eff is not None:\n",
    "        derived_eff = _overall_efficiency(derived_in, derived_out)\n",
    "        if derived_eff is not None and abs(float(yaml_eff) - derived_eff) > eff_tolerance:\n",
    "            print(f\"WARNING: {name} overall_efficiency differs: yaml={float(yaml_eff):.4f} derived={derived_eff:.4f}\")\n",
    "\n",
    "\n",
    "def apply_tech_entries_to_bundle(\n",
    "    techs: Dict[str, TechEntry],\n",
    "    buses: pd.DataFrame,\n",
    "    generators: pd.DataFrame,\n",
    "    links: pd.DataFrame,\n",
    "    stores: pd.DataFrame,\n",
    " ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Apply YAML tech entries to the CSV tables; return (gens, links, stores, summary_df).\"\"\"\n",
    "    rows = []\n",
    "    for name, entry in techs.items():\n",
    "        if entry.component_type == \"generator\":\n",
    "            if name not in generators.index:\n",
    "                raise ValueError(f\"YAML tech '{name}' is generator but not present in generators.csv\")\n",
    "            annual_out = annualised_capital_cost(\n",
    "                entry.overnight_cost_per_mw, entry.interest_rate, entry.lifetime_years, entry.fixed_om_fraction\n",
    "            )\n",
    "            generators.loc[name, \"capital_cost\"] = annual_out\n",
    "            rows.append({\"tech\": name, \"component\": \"generator\", \"annual_capital_cost_usd_per_mw\": annual_out})\n",
    "\n",
    "        elif entry.component_type == \"store\":\n",
    "            if name not in stores.index:\n",
    "                raise ValueError(f\"YAML tech '{name}' is store but not present in stores.csv\")\n",
    "            annual = annualised_capital_cost(\n",
    "                entry.overnight_cost_per_mwh, entry.interest_rate, entry.lifetime_years, entry.fixed_om_fraction\n",
    "            )\n",
    "            stores.loc[name, \"capital_cost\"] = annual\n",
    "            rows.append({\"tech\": name, \"component\": \"store\", \"annual_capital_cost_usd_per_mwh\": annual})\n",
    "\n",
    "        elif entry.component_type == \"link\":\n",
    "            if name not in links.index:\n",
    "                raise ValueError(f\"YAML tech '{name}' is link but not present in links.csv\")\n",
    "\n",
    "            link_row = links.loc[name]\n",
    "            bus0 = str(link_row[\"bus0\"])\n",
    "            bus1 = str(link_row[\"bus1\"])\n",
    "            bus2 = link_row.get(\"bus2\")\n",
    "            bus2_present = bus2 is not None and str(bus2).strip() not in (\"\", \"nan\", \"NaN\")\n",
    "\n",
    "            # If YAML provides a recipe, derive link coefficients from it (supports bus2).\n",
    "            if entry.carriers_in is not None and entry.carriers_out is not None:\n",
    "                if bus1 not in entry.carriers_out:\n",
    "                    raise ValueError(\n",
    "                        f\"techs.{name}.carriers_out must include primary output bus '{bus1}' (value typically 1.0)\"\n",
    "                    )\n",
    "                if bus0 not in entry.carriers_in:\n",
    "                    raise ValueError(\n",
    "                        f\"techs.{name}.carriers_in must include bus0 '{bus0}' (power/input basis)\"\n",
    "                    )\n",
    "                power_in = float(entry.carriers_in[bus0])\n",
    "                if power_in <= 0:\n",
    "                    raise ValueError(f\"techs.{name}.carriers_in.{bus0} must be > 0\")\n",
    "                primary_out = float(entry.carriers_out[bus1])\n",
    "                if primary_out <= 0:\n",
    "                    raise ValueError(f\"techs.{name}.carriers_out.{bus1} must be > 0\")\n",
    "\n",
    "                eff1 = primary_out / power_in\n",
    "                links.loc[name, \"efficiency\"] = eff1\n",
    "\n",
    "                if bus2_present:\n",
    "                    bus2_name = str(bus2)\n",
    "                    if bus2_name in (entry.carriers_in or {}):\n",
    "                        amt = float(entry.carriers_in[bus2_name])\n",
    "                        eff2 = -amt / power_in\n",
    "                        links.loc[name, \"efficiency2\"] = eff2\n",
    "                        links.loc[name, \"bus2\"] = bus2_name\n",
    "                    elif bus2_name in (entry.carriers_out or {}):\n",
    "                        amt = float(entry.carriers_out[bus2_name])\n",
    "                        eff2 = amt / power_in\n",
    "                        links.loc[name, \"efficiency2\"] = eff2\n",
    "                        links.loc[name, \"bus2\"] = bus2_name\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"techs.{name} link has bus2='{bus2_name}' but YAML recipe omits it from carriers_in/out\"\n",
    "                        )\n",
    "\n",
    "                # Compare YAML recipe against what the coefficients imply (sanity check)\n",
    "                derived_in, derived_out = _recipe_from_link_row(links.loc[name])\n",
    "                _warn_if_recipe_mismatch(\n",
    "                    name,\n",
    "                    entry.carriers_in,\n",
    "                    entry.carriers_out,\n",
    "                    derived_in,\n",
    "                    derived_out,\n",
    "                    entry.overall_efficiency,\n",
    "                )\n",
    "                eff_ref = _overall_efficiency(derived_in, derived_out)\n",
    "            else:\n",
    "                # No recipe: keep existing efficiencies, but require recipes for multi-input links.\n",
    "                if bus2_present:\n",
    "                    raise ValueError(\n",
    "                        f\"techs.{name} is a multi-input/output link (has bus2) so YAML must provide carriers_in/carriers_out\"\n",
    "                    )\n",
    "                eff_ref = None\n",
    "\n",
    "            annual_out = annualised_capital_cost(\n",
    "                entry.overnight_cost_per_mw, entry.interest_rate, entry.lifetime_years, entry.fixed_om_fraction\n",
    "            )\n",
    "            # YAML link costs are output-basis (MW_out on bus1); convert to PyPSA input-basis (MW_in on bus0).\n",
    "            annual_in = link_cost_mw_out_to_mw_in(annual_out, float(links.loc[name, \"efficiency\"]))\n",
    "\n",
    "            links.loc[name, \"capital_cost\"] = annual_in\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"tech\": name,\n",
    "                    \"component\": \"link\",\n",
    "                    \"efficiency_bus0_to_bus1\": float(links.loc[name, \"efficiency\"]),\n",
    "                    \"efficiency2\": (None if not bus2_present else float(links.loc[name, \"efficiency2\"])) ,\n",
    "                    \"annual_cost_usd_per_mw_out\": annual_out,\n",
    "                    \"annual_cost_usd_per_mw_in\": annual_in,\n",
    "                    \"overall_efficiency_derived\": eff_ref,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported component_type: {entry.component_type}\")\n",
    "\n",
    "    summary = pd.DataFrame(rows)\n",
    "    return generators, links, stores, summary\n",
    "\n",
    "\n",
    "# Load YAML + bundle, apply, and optionally write\n",
    "if not TECH_YAML.exists():\n",
    "    raise FileNotFoundError(f\"Tech YAML not found: {TECH_YAML}\")\n",
    "if not PLANT_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Plant directory not found: {PLANT_DIR}\")\n",
    "\n",
    "techs = load_tech_yaml(TECH_YAML)\n",
    "buses_df, gens_df, links_df, stores_df = load_csv_bundle(PLANT_DIR)\n",
    "\n",
    "updated_gens, updated_links, updated_stores, summary_df = apply_tech_entries_to_bundle(\n",
    "    techs, buses_df, gens_df.copy(), links_df.copy(), stores_df.copy()\n",
    " )\n",
    "\n",
    "# Write outputs\n",
    "if WRITE_OUTPUTS:\n",
    "    (PLANT_DIR / \"generators.csv\").write_text(updated_gens.reset_index(drop=True).to_csv(index=False))\n",
    "    (PLANT_DIR / \"links.csv\").write_text(updated_links.reset_index(drop=True).to_csv(index=False))\n",
    "    (PLANT_DIR / \"stores.csv\").write_text(updated_stores.reset_index(drop=True).to_csv(index=False))\n",
    "    print(\"Wrote updated CSV tables to:\", PLANT_DIR)\n",
    "else:\n",
    "    print(\"WRITE_OUTPUTS=False: not writing any files\")\n",
    "\n",
    "# Confirm by reloading and comparing key columns for configured techs\n",
    "re_buses, re_gens, re_links, re_stores = load_csv_bundle(PLANT_DIR)\n",
    "\n",
    "checks = []\n",
    "for name, entry in techs.items():\n",
    "    if entry.component_type == \"generator\":\n",
    "        checks.append((name, \"generator\", float(re_gens.loc[name, \"capital_cost\"])))\n",
    "    elif entry.component_type == \"store\":\n",
    "        checks.append((name, \"store\", float(re_stores.loc[name, \"capital_cost\"])))\n",
    "    elif entry.component_type == \"link\":\n",
    "        checks.append((name, \"link\", float(re_links.loc[name, \"capital_cost\"])))\n",
    "\n",
    "check_df = pd.DataFrame(checks, columns=[\"tech\", \"component\", \"capital_cost_written\"])\n",
    "display(summary_df)\n",
    "display(check_df.sort_values([\"component\", \"tech\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
